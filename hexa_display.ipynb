{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "In this assignment we are using feed forward neural network to print an hexadecimal output from a given binary input.We are using neural network to replace a complex electric circuit to convert 4 inputs into an seven segment display which would save lot of time and energy.In this we will take 4 inputs and convert them into seven outputs to print it on a seven segment display.\n",
    "\n",
    "How does a neural network work?  \n",
    "This is a network of layers and nodes where each layer does a differnt task and the data which is fed into it is processed at each layer and that output is fed into the next one, and by the time it reaches the last layer it is been through many nodes and is been processed differently and has been altered at each node and layer,our brain also works in a similar way to derive a conclusion, when certain information is fed into it, we think from differnt perspectives and situations to come to a conclusion, as these both work in a similar fashion this technology got its name.\n",
    "\n",
    "What is a Node?  \n",
    "It is the basic unit of the neural network where a function is been applied, it takes multiple inputs with weights and applies the desired function based on the weights we assign to the each node and computes an output.\n",
    "\n",
    "What is feed forward neural network?  \n",
    "As the name suggests the input is carried from one node to the other, in which the input is processed at a node and the output of that node is carried forward and becomes the input for the next node and so on. In this network we use multiple layers, and the data gets processed at each layer.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing the necessary libraries\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy, random, os\n",
    "\n",
    "# keras libraries\n",
    "from numpy import loadtxt\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense,Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# load the dataset\n",
    "dataset = loadtxt('hexa_display.csv', delimiter=',')\n",
    "# split into input (X) and output (y) variables here we are taking the first 4 columns as inputs and the rest as outputs\n",
    "X = dataset[:,0:4]\n",
    "y = dataset[:,4:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 1., 1., 1., 1., 1., 0.],\n",
       "       [0., 1., 1., 0., 0., 0., 0.],\n",
       "       [1., 1., 0., 1., 1., 0., 1.],\n",
       "       [1., 1., 1., 1., 0., 0., 1.],\n",
       "       [0., 1., 1., 0., 0., 1., 1.],\n",
       "       [1., 0., 1., 1., 0., 1., 1.],\n",
       "       [1., 0., 1., 1., 1., 1., 1.],\n",
       "       [1., 1., 1., 0., 0., 0., 0.],\n",
       "       [1., 1., 1., 1., 1., 1., 1.],\n",
       "       [1., 1., 1., 1., 0., 1., 1.],\n",
       "       [1., 1., 1., 0., 1., 1., 1.],\n",
       "       [0., 0., 1., 1., 1., 1., 1.],\n",
       "       [1., 0., 0., 1., 1., 1., 0.],\n",
       "       [0., 1., 1., 1., 1., 0., 1.],\n",
       "       [1., 0., 0., 1., 1., 1., 1.],\n",
       "       [1., 0., 0., 0., 1., 1., 1.]])"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#checking our data in y\n",
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we are creating our model with three layers and we are defining the number of nodes, type of function we are using in each layer and also using droupout which would help in preventing overfitting it restricts the use of some of the nodes randomly so it doesnt overfit the output.Here we are using activation layers as relu and sigmoid.The relu funtion will simply give the input if it is positive else it will give zero as output it also works faster than sigmoid function. Sigmoid function works in a similar fashion to logistic regression and gives the output as one or zero,we are using these functions in these layers because we want our outputs to be 1 or 0, for switching on our desired circuits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# defining the keras model\n",
    "model = Sequential()\n",
    "#here we are setting the number of nodes, input parameters and the algorithm used for 1st layer\n",
    "model.add(Dense(30, input_dim=4, activation='relu'))\n",
    "#it is used to prevent overfitting\n",
    "model.add(Dropout(0.2))\n",
    "#we are using 22 hidden nodes with relu function, 2nd layer\n",
    "model.add(Dense(22, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "#we are using 7 nodes as we only need 7 outputs and sigmoid as activation function as we need our output to be 1 or 0\n",
    "model.add(Dense(7, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compile the keras model\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Batch size and epoch are hyperparameters in which both work as for loop to itetrate through the data and batch size acts as a nested for loop inside the epoch for loop, here in our case we are running 4 times the same data through all the nodes to get the output and each time we are running it we are running through the whole batch size. I.e we are running the whole data in each batch before updating it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 12 samples, validate on 4 samples\n",
      "Epoch 1/4\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.3283 - accuracy: 0.8690 - val_loss: 1.6263 - val_accuracy: 0.6071\n",
      "Epoch 2/4\n",
      "12/12 [==============================] - 0s 463us/step - loss: 0.2475 - accuracy: 0.9048 - val_loss: 1.6291 - val_accuracy: 0.6071\n",
      "Epoch 3/4\n",
      "12/12 [==============================] - 0s 741us/step - loss: 0.2630 - accuracy: 0.9048 - val_loss: 1.6318 - val_accuracy: 0.6071\n",
      "Epoch 4/4\n",
      "12/12 [==============================] - 0s 744us/step - loss: 0.2898 - accuracy: 0.8929 - val_loss: 1.6347 - val_accuracy: 0.6071\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x1a3fcf9f60>"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit the keras model on the dataset\n",
    "model.fit(X, y, epochs=4, batch_size=16,validation_split=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We should be careful while selecting the number of epochs, as after a certain number of epochs our accuracy starts dropping and we have to figure out where it is changing and select the best epochs to get more accurcy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 198us/step\n",
      "Accuracy: 83.04\n"
     ]
    }
   ],
   "source": [
    "# evaluating our model\n",
    "_, accuracy = model.evaluate(X, y)\n",
    "print('Accuracy: %.2f' % (accuracy*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.8351643 , 0.81571984, 0.8940244 , 0.595598  , 0.69683194,\n",
       "        0.871526  , 0.6116091 ],\n",
       "       [0.50875044, 0.80298156, 0.97878945, 0.3362398 , 0.03316364,\n",
       "        0.21599287, 0.19724822],\n",
       "       [0.9471343 , 0.85934514, 0.3733492 , 0.785686  , 0.88580966,\n",
       "        0.28286064, 0.8549864 ],\n",
       "       [0.8723745 , 0.82034075, 0.91614854, 0.7461647 , 0.12427038,\n",
       "        0.04724562, 0.6804404 ],\n",
       "       [0.34462982, 0.73749197, 0.9990897 , 0.34333783, 0.11610115,\n",
       "        0.99243224, 0.91395795],\n",
       "       [0.63181806, 0.5304072 , 0.99747384, 0.6013276 , 0.03175643,\n",
       "        0.86566097, 0.78991604],\n",
       "       [0.7991234 , 0.5016501 , 0.9401224 , 0.6463005 , 0.82940304,\n",
       "        0.91526747, 0.915884  ],\n",
       "       [0.81609505, 0.65768903, 0.963698  , 0.5857509 , 0.04611129,\n",
       "        0.11092857, 0.47747996],\n",
       "       [0.9753566 , 0.9224229 , 0.99515104, 0.86519265, 0.985405  ,\n",
       "        0.9996425 , 0.9946284 ],\n",
       "       [0.69643575, 0.8567632 , 0.9992404 , 0.8088832 , 0.23694941,\n",
       "        0.9866371 , 0.9659836 ],\n",
       "       [0.9533509 , 0.82525665, 0.97661674, 0.7459401 , 0.9901145 ,\n",
       "        0.99770033, 0.98757565],\n",
       "       [0.5499844 , 0.5487627 , 0.9909116 , 0.7745327 , 0.64233387,\n",
       "        0.95621175, 0.96813023],\n",
       "       [0.8449359 , 0.89380467, 0.99991333, 0.70839167, 0.84714717,\n",
       "        0.999943  , 0.99784684],\n",
       "       [0.5296133 , 0.62966037, 0.99990445, 0.7624197 , 0.09089515,\n",
       "        0.997717  , 0.99024284],\n",
       "       [0.87531674, 0.7101595 , 0.9974191 , 0.70870155, 0.9756439 ,\n",
       "        0.9993185 , 0.9952558 ],\n",
       "       [0.6805793 , 0.47714645, 0.9983698 , 0.7201846 , 0.4037993 ,\n",
       "        0.9869132 , 0.9729867 ]], dtype=float32)"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# here we are checking our output values\n",
    "predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we are converting our outputs into 1 or 0 based on 0.5 threshold as we need the output to be 1 or 0 to turn on a circuit equally bright."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "#converting our predictions\n",
    "B = numpy.where(predictions > 0.5, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 1, 1, 1, 1, 1, 1],\n",
       "       [1, 1, 1, 0, 0, 0, 0],\n",
       "       [1, 1, 0, 1, 1, 0, 1],\n",
       "       [1, 1, 1, 1, 0, 0, 1],\n",
       "       [0, 1, 1, 0, 0, 1, 1],\n",
       "       [1, 1, 1, 1, 0, 1, 1],\n",
       "       [1, 1, 1, 1, 1, 1, 1],\n",
       "       [1, 1, 1, 1, 0, 0, 0],\n",
       "       [1, 1, 1, 1, 1, 1, 1],\n",
       "       [1, 1, 1, 1, 0, 1, 1],\n",
       "       [1, 1, 1, 1, 1, 1, 1],\n",
       "       [1, 1, 1, 1, 1, 1, 1],\n",
       "       [1, 1, 1, 1, 1, 1, 1],\n",
       "       [1, 1, 1, 1, 0, 1, 1],\n",
       "       [1, 1, 1, 1, 1, 1, 1],\n",
       "       [1, 0, 1, 1, 0, 1, 1]])"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#predicted data\n",
    "B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 1., 1., 1., 1., 1., 0.],\n",
       "       [0., 1., 1., 0., 0., 0., 0.],\n",
       "       [1., 1., 0., 1., 1., 0., 1.],\n",
       "       [1., 1., 1., 1., 0., 0., 1.],\n",
       "       [0., 1., 1., 0., 0., 1., 1.],\n",
       "       [1., 0., 1., 1., 0., 1., 1.],\n",
       "       [1., 0., 1., 1., 1., 1., 1.],\n",
       "       [1., 1., 1., 0., 0., 0., 0.],\n",
       "       [1., 1., 1., 1., 1., 1., 1.],\n",
       "       [1., 1., 1., 1., 0., 1., 1.],\n",
       "       [1., 1., 1., 0., 1., 1., 1.],\n",
       "       [0., 0., 1., 1., 1., 1., 1.],\n",
       "       [1., 0., 0., 1., 1., 1., 0.],\n",
       "       [0., 1., 1., 1., 1., 0., 1.],\n",
       "       [1., 0., 0., 1., 1., 1., 1.],\n",
       "       [1., 0., 0., 0., 1., 1., 1.]])"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#actual data\n",
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "Our model seems to work well and we got an accuracy of 83.04% which is good, and this whole model took very less time compared to building the whole circuit manually and also saved lot of time and we can further try to improve the model and we also do not get affected by circuitry mistakes or IC blowouts due to which our model is more trustworthy. We also learned to train and build an neural network on the way to solve our problem.We also got rid of spending money on buying all the components, the output we are generating is also very stable and bright."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Refernces\n",
    "\n",
    "\n",
    "Brownlee, J. (2019, August 6). A Gentle Introduction to the Rectified Linear Unit (ReLU). Retrieved from https://machinelearningmastery.com/rectified-linear-activation-function-for-deep-learning-neural-networks/.  \n",
    "\n",
    "Brownlee, J. (2019, October 25). Difference Between a Batch and an Epoch in a Neural Network. Retrieved from https://machinelearningmastery.com/difference-between-a-batch-and-an-epoch/."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
